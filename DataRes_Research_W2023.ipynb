{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Reddit Social Network Analysis\n",
        "#### DataRes Research - Winter 2023"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i3QEigIWKR5M"
      },
      "source": [
        "## Import libraries, packages, env"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hIh8YnFCw4e6",
        "outputId": "5bfc535b-67dc-4089-d6be-4c81429a4e4f"
      },
      "outputs": [],
      "source": [
        "# !pip3 install colab-env\n",
        "# !pip3 install praw\n",
        "# !pip3 install torch\n",
        "# !pip3 install pyg-lib torch-scatter torch-sparse torch-cluster torch-spline-conv torch-geometric -f https://data.pyg.org/whl/torch-1.13.0+cu117.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "lbpEZ34CUxzP"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "OTf4OUTbcmBZ"
      },
      "outputs": [],
      "source": [
        "CUDA = 12.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "nPHHhAkVV2G2"
      },
      "outputs": [],
      "source": [
        "import argparse\n",
        "import os, sys \n",
        "import os.path as osp\n",
        "from typing import Callable, List, Optional\n",
        "\n",
        "# Reddit API\n",
        "import praw\n",
        "\n",
        "# General\n",
        "from matplotlib import pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime, timedelta\n",
        "import copy\n",
        "\n",
        "import scipy.sparse as sp\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "yPnhszGCZnc5"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torch.nn import (\n",
        "    ModuleList,\n",
        "    Linear,\n",
        ")\n",
        "from torch.nn.functional import dropout, relu\n",
        "\n",
        "from torch_geometric.data import (\n",
        "    Data,\n",
        "    InMemoryDataset,\n",
        "    download_url,\n",
        "    extract_zip,\n",
        "    DataLoader,\n",
        "    NeighborSampler,\n",
        ")\n",
        "from torch_geometric.utils import (\n",
        "    coalesce,\n",
        "    to_networkx,\n",
        "    train_test_split_edges,\n",
        "    add_self_loops, \n",
        "    degree,\n",
        ")\n",
        "from torch_geometric.nn import (\n",
        "    GAT, \n",
        "    GATConv,\n",
        "    SAGEConv,\n",
        "    global_max_pool,\n",
        "    global_mean_pool,\n",
        "    MessagePassing,\n",
        ")\n",
        "\n",
        "import torch_geometric.transforms as T\n",
        "\n",
        "from torch_geometric.logging import init_wandb, log\n",
        "\n",
        "from torch_geometric.loader import NeighborLoader, DataLoader\n",
        "\n",
        "from torch_geometric.datasets import Reddit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6tCGTQ2vrxj8",
        "outputId": "f2d17b36-32a9-410b-d11e-e46f3cbb1d53"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.13.1+cu117\n"
          ]
        }
      ],
      "source": [
        "print(torch.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "uUAZz-eJpT75"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "path = 'Datasets'\n",
        "\n",
        "dataset = Reddit(path, transform=None)\n",
        "\n",
        "# if not os.path.exists(path):\n",
        "#     dataset = Reddit(path, transform=None)\n",
        "# else:\n",
        "#     # Dataset already exists, so skip creating it\n",
        "#     print('Dataset already exists at', path)\n",
        "#     dataset = torch.load('Datasets/processed/data.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NZ-yonJTo0hT",
        "outputId": "5f49df36-fef1-493b-832c-51bfd61ce853"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Reddit()"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Data(x=[232965, 602], edge_index=[2, 114615892], y=[232965], train_mask=[232965], val_mask=[232965], test_mask=[232965])"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YdBAZpdPtXWy"
      },
      "source": [
        "# Reddit Dataset EDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gwN8HH0MtifV",
        "outputId": "22e6b02f-3f70-47b7-d3fd-ca4a0ee3b615"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Reddit()"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 1.2334,  9.0430, -0.9233,  ..., -0.2579,  0.3112, -0.3772],\n",
              "        [-0.1386, -0.2022,  0.1277,  ...,  0.1563,  0.1048, -0.6534],\n",
              "        [-0.1330, -0.1962, -0.0296,  ...,  0.0358,  0.2864,  0.2744],\n",
              "        ...,\n",
              "        [-0.0614, -0.2022,  0.9698,  ...,  1.1064, -1.4323, -0.2398],\n",
              "        [-0.1606, -0.2022, -0.0892,  ...,  0.7440, -0.5046, -2.2288],\n",
              "        [ 0.0929,  0.2822,  0.1768,  ...,  0.2196,  0.5967,  0.5588]])"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset[0].x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IhiWalNkyWF9",
        "outputId": "f8068f17-afa5-4907-e9bd-a400df120e2d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([2, 114615892])"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset[0].edge_index.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ux0UGHuOy5Uo",
        "outputId": "0541c9d9-8944-434b-8ce7-3a92c0f79c7b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[     0,    242],\n",
              "       [     0,    249],\n",
              "       [     0,    524],\n",
              "       ...,\n",
              "       [232964, 231806],\n",
              "       [232964, 232594],\n",
              "       [232964, 232634]])"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset[0].edge_index.t().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(114615892, 2)"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset[0].edge_index.t().numpy().shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vcozlaRIRdH-",
        "outputId": "5a65f02e-21e0-4950-cbb3-d1d413b48d0a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of nodes: 232965\n",
            "Number of edges: 114615892\n"
          ]
        }
      ],
      "source": [
        "# Get the number of nodes and edges in the dataset\n",
        "num_nodes = dataset[0].num_nodes\n",
        "num_edges = dataset[0].num_edges\n",
        "\n",
        "# Print some information about the dataset\n",
        "print(\"Number of nodes:\", num_nodes)\n",
        "print(\"Number of edges:\", num_edges)\n",
        "\n",
        "# # Get the node features as a numpy array\n",
        "node_features = dataset[0].x.numpy()\n",
        "\n",
        "# # Plot a histogram of the node features\n",
        "# plt.hist(node_features.flatten(), bins='auto')\n",
        "# plt.title(\"Histogram of Node Features\")\n",
        "# plt.xlabel(\"Node Feature Value\")\n",
        "# plt.ylabel(\"Frequency\")\n",
        "# plt.show()\n",
        "# plt.close()\n",
        "\n",
        "del node_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "83_ZX9SaTX9J",
        "outputId": "7c347390-9899-40e5-eae9-ccb4669074da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Adjacency matrix sparsity: 0.9978881389258081\n"
          ]
        }
      ],
      "source": [
        "# Compute the sparsity of the adjacency matrix\n",
        "edge_index = dataset[0].edge_index\n",
        "adjacency_matrix = sp.coo_matrix((torch.ones(num_edges), edge_index), shape=(num_nodes, num_nodes))\n",
        "sparsity = 1 - (num_edges / (num_nodes * (num_nodes - 1)))\n",
        "print(\"Adjacency matrix sparsity:\", sparsity)\n",
        "\n",
        "# # Plot the adjacency matrix\n",
        "# plt.spy(adjacency_matrix, markersize=0.1)\n",
        "# plt.title(\"Adjacency Matrix\")\n",
        "# plt.xlabel(\"Node ID\")\n",
        "# plt.ylabel(\"Node ID\")\n",
        "# plt.show()\n",
        "\n",
        "del edge_index, adjacency_matrix, sparsity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TX-T2aRNNWi0",
        "outputId": "99a3f4a2-bfed-4ca6-ed8a-8d37f1423bd4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([30, 17, 18,  ...,  3, 13, 13])"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Community of graph 0\n",
        "dataset[0].y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "03zp11waP0v0",
        "outputId": "3d896ca7-1a40-48b5-8c61-3af63955dc13"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "41\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "tensor([[ 1.2334,  9.0430, -0.9233,  ..., -1.2256, -0.3788, -1.3944],\n",
              "        [-0.1386, -0.2022,  0.1277,  ...,  0.6615,  0.5723,  0.2782],\n",
              "        [-0.1330, -0.1962, -0.0296,  ..., -0.6425,  1.1302, -1.7275],\n",
              "        ...,\n",
              "        [-0.0614, -0.2022,  0.9698,  ..., -0.7903, -0.6344, -2.5713],\n",
              "        [-0.1606, -0.2022, -0.0892,  ...,  0.0801,  0.7868,  0.2527],\n",
              "        [ 0.0929,  0.2822,  0.1768,  ...,  0.4616, -0.7446,  0.6888]])"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Subreddits (one-hot encoded) of graph 0\n",
        "num_subreddits = dataset.num_classes\n",
        "print(num_subreddits)\n",
        "dataset[0].x[:, :num_subreddits]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Node Classification Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "CZoB7aR5xO9D"
      },
      "outputs": [],
      "source": [
        "# Already send node features/labels to GPU for faster access during sampling:\n",
        "data = dataset[0].to(device, 'x', 'y')\n",
        "\n",
        "kwargs = {'batch_size': 512, 'num_workers': 6, 'persistent_workers': True}\n",
        "train_loader = NeighborLoader(data, input_nodes=data.train_mask,\n",
        "                              num_neighbors=[25, 10], shuffle=True, **kwargs)\n",
        "\n",
        "subgraph_loader = NeighborLoader(copy.copy(data), input_nodes=None,\n",
        "                                 num_neighbors=[-1], shuffle=False, **kwargs)\n",
        "\n",
        "# No need to maintain these features during evaluation:\n",
        "del subgraph_loader.data.x, subgraph_loader.data.y\n",
        "\n",
        "# Add global node index information.\n",
        "subgraph_loader.data.num_nodes = data.num_nodes\n",
        "subgraph_loader.data.n_id = torch.arange(data.num_nodes)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "a2_VYoh2tjtu"
      },
      "source": [
        "## SAGE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "bKcJWgQ2zGxm"
      },
      "outputs": [],
      "source": [
        "class SAGE(torch.nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.convs = torch.nn.ModuleList()\n",
        "        self.convs.append(SAGEConv(in_channels, hidden_channels))\n",
        "        self.convs.append(SAGEConv(hidden_channels, out_channels))\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        for i, conv in enumerate(self.convs):\n",
        "            x = conv(x, edge_index)\n",
        "            if i < len(self.convs) - 1:\n",
        "                x = x.relu_()\n",
        "                x = F.dropout(x, p=0.5, training=self.training)\n",
        "        return x\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def inference(self, x_all, subgraph_loader):\n",
        "        pbar = tqdm(total=len(subgraph_loader.dataset) * len(self.convs))\n",
        "        pbar.set_description('Evaluating')\n",
        "\n",
        "        # Compute representations of nodes layer by layer, using *all*\n",
        "        # available edges. This leads to faster computation in contrast to\n",
        "        # immediately computing the final representations of each batch:\n",
        "        for i, conv in enumerate(self.convs):\n",
        "            xs = []\n",
        "            for batch in subgraph_loader:\n",
        "                x = x_all[batch.n_id.to(x_all.device)].to(device)\n",
        "                x = conv(x, batch.edge_index.to(device))\n",
        "                if i < len(self.convs) - 1:\n",
        "                    x = x.relu_()\n",
        "                xs.append(x[:batch.batch_size].cpu())\n",
        "                pbar.update(batch.batch_size)\n",
        "            x_all = torch.cat(xs, dim=0)\n",
        "        pbar.close()\n",
        "        return x_all"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "DWi0jtxezH0u"
      },
      "outputs": [],
      "source": [
        "model = SAGE(dataset.num_features, 256, dataset.num_classes).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "7W2vlr1Aza15"
      },
      "outputs": [],
      "source": [
        "def train(epoch):\n",
        "    model.train()\n",
        "\n",
        "    pbar = tqdm(total=int(len(train_loader.dataset)))\n",
        "    pbar.set_description(f'Epoch {epoch:02d}')\n",
        "\n",
        "    total_loss = total_correct = total_examples = 0\n",
        "    for batch in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        y = batch.y[:batch.batch_size]\n",
        "        y_hat = model(batch.x, batch.edge_index.to(device))[:batch.batch_size]\n",
        "        loss = F.cross_entropy(y_hat, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += float(loss) * batch.batch_size\n",
        "        total_correct += int((y_hat.argmax(dim=-1) == y).sum())\n",
        "        total_examples += batch.batch_size\n",
        "        pbar.update(batch.batch_size)\n",
        "    pbar.close()\n",
        "\n",
        "    return total_loss / total_examples, total_correct / total_examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "2Yd_EPzZzfM0"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def test():\n",
        "    model.eval()\n",
        "    y_hat = model.inference(data.x, subgraph_loader).argmax(dim=-1)\n",
        "    y = data.y.to(y_hat.device)\n",
        "\n",
        "    accs = []\n",
        "    for mask in [data.train_mask, data.val_mask, data.test_mask]:\n",
        "        accs.append(int((y_hat[mask] == y[mask]).sum()) / int(mask.sum()))\n",
        "    return accs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "chYQC2wNzsVS",
        "outputId": "73ecbae5-4820-4d1a-e49c-82b5b0fb2131"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 01: 100%|██████████| 153431/153431 [00:05<00:00, 29826.91it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 01, Loss: 1.7085, Approx. Train: 0.6054\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|██████████| 465930/465930 [00:20<00:00, 22740.99it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 01, Train: 0.8607, Val: 0.8728, Test: 0.8672\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 02: 100%|██████████| 153431/153431 [00:04<00:00, 35275.86it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 02, Loss: 0.5583, Approx. Train: 0.8760\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|██████████| 465930/465930 [00:20<00:00, 22780.65it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 02, Train: 0.9325, Val: 0.9371, Test: 0.9355\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 03: 100%|██████████| 153431/153431 [00:04<00:00, 35705.81it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 03, Loss: 0.3764, Approx. Train: 0.9152\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|██████████| 465930/465930 [00:20<00:00, 22679.30it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 03, Train: 0.9430, Val: 0.9476, Test: 0.9451\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 04: 100%|██████████| 153431/153431 [00:04<00:00, 35020.20it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 04, Loss: 0.3133, Approx. Train: 0.9275\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|██████████| 465930/465930 [00:22<00:00, 20743.52it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 04, Train: 0.9482, Val: 0.9511, Test: 0.9490\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 05: 100%|██████████| 153431/153431 [00:04<00:00, 34457.14it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 05, Loss: 0.2789, Approx. Train: 0.9339\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|██████████| 465930/465930 [00:20<00:00, 22920.90it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 05, Train: 0.9521, Val: 0.9541, Test: 0.9526\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 06: 100%|██████████| 153431/153431 [00:04<00:00, 35205.69it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 06, Loss: 0.2568, Approx. Train: 0.9373\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|██████████| 465930/465930 [00:21<00:00, 22059.94it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 06, Train: 0.9543, Val: 0.9558, Test: 0.9542\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 07: 100%|██████████| 153431/153431 [00:04<00:00, 34052.95it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 07, Loss: 0.2397, Approx. Train: 0.9417\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|██████████| 465930/465930 [00:22<00:00, 20441.96it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 07, Train: 0.9561, Val: 0.9570, Test: 0.9555\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 08: 100%|██████████| 153431/153431 [00:04<00:00, 35335.88it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 08, Loss: 0.2259, Approx. Train: 0.9443\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|██████████| 465930/465930 [00:23<00:00, 19738.68it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 08, Train: 0.9581, Val: 0.9578, Test: 0.9568\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 09: 100%|██████████| 153431/153431 [00:04<00:00, 34478.68it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 09, Loss: 0.2159, Approx. Train: 0.9459\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|██████████| 465930/465930 [00:23<00:00, 19710.68it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 09, Train: 0.9595, Val: 0.9588, Test: 0.9581\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 10: 100%|██████████| 153431/153431 [00:04<00:00, 35437.64it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10, Loss: 0.2066, Approx. Train: 0.9477\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|██████████| 465930/465930 [00:29<00:00, 15793.56it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 10, Train: 0.9607, Val: 0.9597, Test: 0.9587\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "sage_train_accs, sage_val_accs, sage_test_accs = [], [], []\n",
        "\n",
        "for epoch in range(1, 11):\n",
        "    loss, acc = train(epoch)\n",
        "    print(f'Epoch {epoch:02d}, Loss: {loss:.4f}, Approx. Train: {acc:.4f}')\n",
        "    train_acc, val_acc, test_acc = test()\n",
        "    print(f'Epoch: {epoch:02d}, Train: {train_acc:.4f}, Val: {val_acc:.4f}, '\n",
        "          f'Test: {test_acc:.4f}')\n",
        "\n",
        "    # store accuracy values for SAGE\n",
        "    sage_train_accs.append(train_acc)\n",
        "    sage_val_accs.append(val_acc)\n",
        "    sage_test_accs.append(test_acc)\n",
        "    \n",
        "    # delete intermediate tensors\n",
        "    del loss, acc, train_acc, val_acc, test_acc"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Graph Attention Network (GAT)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "class GAT(torch.nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.convs = torch.nn.ModuleList()\n",
        "        self.convs.append(GATConv(in_channels, hidden_channels, heads=8, dropout=0.2))\n",
        "        self.convs.append(GATConv(hidden_channels * 8, out_channels, heads=1, dropout=0.2))\n",
        "        self.activation = nn.LeakyReLU()\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        for i, conv in enumerate(self.convs):\n",
        "            x = conv(x, edge_index)\n",
        "            if i < len(self.convs) - 1:\n",
        "                x = self.activation(x)\n",
        "        return x\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def inference(self, x_all, subgraph_loader):\n",
        "        pbar = tqdm(total=len(subgraph_loader.dataset) * len(self.convs))\n",
        "        pbar.set_description('Evaluating')\n",
        "\n",
        "        # Compute representations of nodes layer by layer, using *all*\n",
        "        # available edges. This leads to faster computation in contrast to\n",
        "        # immediately computing the final representations of each batch:\n",
        "        for i, conv in enumerate(self.convs):\n",
        "            xs = []\n",
        "            for batch in subgraph_loader:\n",
        "                x = x_all[batch.n_id.to(x_all.device)].to(device)\n",
        "                x = conv(x, batch.edge_index.to(device))\n",
        "                if i < len(self.convs) - 1:\n",
        "                    x = self.activation(x)\n",
        "                xs.append(x[:batch.batch_size].cpu())\n",
        "                pbar.update(batch.batch_size)\n",
        "            x_all = torch.cat(xs, dim=0)\n",
        "        pbar.close()\n",
        "        return x_all"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = GAT(dataset.num_features, 128, dataset.num_classes).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train(epoch):\n",
        "    model.train()\n",
        "\n",
        "    pbar = tqdm(total=int(len(train_loader.dataset)))\n",
        "    pbar.set_description(f'Epoch {epoch:02d}')\n",
        "\n",
        "    total_loss = total_correct = total_examples = 0\n",
        "    for batch in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        y = batch.y[:batch.batch_size]\n",
        "        y_hat = model(batch.x, batch.edge_index.to(device))[:batch.batch_size]\n",
        "        loss = F.cross_entropy(y_hat, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += float(loss) * batch.batch_size\n",
        "        total_correct += int((y_hat.argmax(dim=-1) == y).sum())\n",
        "        total_examples += batch.batch_size\n",
        "        pbar.update(batch.batch_size)\n",
        "    pbar.close()\n",
        "\n",
        "    return total_loss / total_examples, total_correct / total_examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def test():\n",
        "    model.eval()\n",
        "    y_hat = model.inference(data.x, subgraph_loader).argmax(dim=-1)\n",
        "    y = data.y.to(y_hat.device)\n",
        "\n",
        "    accs = []\n",
        "    for mask in [data.train_mask, data.val_mask, data.test_mask]:\n",
        "        accs.append(int((y_hat[mask] == y[mask]).sum()) / int(mask.sum()))\n",
        "    return accs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 01: 100%|██████████| 153431/153431 [00:13<00:00, 11130.66it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 01, Loss: 1.3526, Approx. Train: 0.7096\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|██████████| 465930/465930 [00:59<00:00, 7871.19it/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 01, Train: 0.7631, Val: 0.7789, Test: 0.7846\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 02: 100%|██████████| 153431/153431 [00:17<00:00, 8994.42it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 02, Loss: 0.5967, Approx. Train: 0.8831\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|██████████| 465930/465930 [00:59<00:00, 7872.38it/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 02, Train: 0.8272, Val: 0.8399, Test: 0.8440\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 03: 100%|██████████| 153431/153431 [00:19<00:00, 7872.86it/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 03, Loss: 0.4745, Approx. Train: 0.9030\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|██████████| 465930/465930 [00:48<00:00, 9510.71it/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 03, Train: 0.8556, Val: 0.8649, Test: 0.8686\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 04: 100%|██████████| 153431/153431 [00:12<00:00, 12017.65it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 04, Loss: 0.4210, Approx. Train: 0.9112\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|██████████| 465930/465930 [00:56<00:00, 8296.65it/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 04, Train: 0.8670, Val: 0.8742, Test: 0.8763\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 05: 100%|██████████| 153431/153431 [00:22<00:00, 6924.82it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 05, Loss: 0.3934, Approx. Train: 0.9154\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|██████████| 465930/465930 [00:59<00:00, 7802.81it/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 05, Train: 0.8892, Val: 0.8933, Test: 0.8967\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 06: 100%|██████████| 153431/153431 [00:12<00:00, 12023.22it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 06, Loss: 0.3703, Approx. Train: 0.9193\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|██████████| 465930/465930 [01:12<00:00, 6424.63it/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 06, Train: 0.9042, Val: 0.9079, Test: 0.9105\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 07: 100%|██████████| 153431/153431 [00:12<00:00, 11815.98it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 07, Loss: 0.3558, Approx. Train: 0.9213\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|██████████| 465930/465930 [01:02<00:00, 7431.18it/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 07, Train: 0.9104, Val: 0.9134, Test: 0.9158\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 08: 100%|██████████| 153431/153431 [00:12<00:00, 11946.77it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 08, Loss: 0.3453, Approx. Train: 0.9233\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|██████████| 465930/465930 [00:53<00:00, 8748.37it/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 08, Train: 0.9153, Val: 0.9171, Test: 0.9201\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 09: 100%|██████████| 153431/153431 [00:21<00:00, 6994.70it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 09, Loss: 0.3339, Approx. Train: 0.9248\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|██████████| 465930/465930 [00:51<00:00, 8962.87it/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 09, Train: 0.9210, Val: 0.9246, Test: 0.9269\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 10: 100%|██████████| 153431/153431 [00:12<00:00, 11927.34it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10, Loss: 0.3278, Approx. Train: 0.9254\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|██████████| 465930/465930 [01:00<00:00, 7678.83it/s] "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 10, Train: 0.9287, Val: 0.9305, Test: 0.9328\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "gat_train_accs, gat_val_accs, gat_test_accs = [], [], []\n",
        "\n",
        "for epoch in range(1, 11):\n",
        "    loss, acc = train(epoch)\n",
        "    print(f'Epoch {epoch:02d}, Loss: {loss:.4f}, Approx. Train: {acc:.4f}')\n",
        "    train_acc, val_acc, test_acc = test()\n",
        "    print(f'Epoch: {epoch:02d}, Train: {train_acc:.4f}, Val: {val_acc:.4f}, '\n",
        "          f'Test: {test_acc:.4f}')\n",
        "\n",
        "    # store accuracy values for GAT\n",
        "    gat_train_accs.append(train_acc)\n",
        "    gat_val_accs.append(val_acc)\n",
        "    gat_test_accs.append(test_acc)\n",
        "    \n",
        "    # delete intermediate tensors\n",
        "    del loss, acc, train_acc, val_acc, test_acc"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Accuracy Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# create a list of labels for each epoch\n",
        "epochs = range(1, 11)\n",
        "epoch_labels = [f\"Epoch {i}\" for i in epochs]\n",
        "\n",
        "# plot the comparison bar plot\n",
        "fig, ax = plt.subplots(figsize=(12, 6))\n",
        "bar_width = 0.35\n",
        "opacity = 0.8\n",
        "colors = ['#F66815', '#2267D9']\n",
        "\n",
        "# shift the x coordinates for the second model\n",
        "x = np.array(epochs)\n",
        "\n",
        "ax.bar(x, sage_test_accs, bar_width, alpha=opacity, color=colors[0], label=\"SAGE\")\n",
        "ax.bar(x + bar_width, gat_test_accs, bar_width, alpha=opacity, color=colors[1], label=\"GAT\")\n",
        "ax.set_ylim(bottom=0.75)\n",
        "\n",
        "ax.set_xlabel('Epochs')\n",
        "ax.set_ylabel('Test Accuracy')\n",
        "ax.set_xticks(np.array(epochs) + bar_width / 2)\n",
        "ax.set_xticklabels(epoch_labels)\n",
        "ax.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "2Ss4pd7FKA5L"
      },
      "source": [
        "# Data Collection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "from dotenv import load_dotenv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "4a-y717qSKkL"
      },
      "outputs": [],
      "source": [
        "load_dotenv()\n",
        "\n",
        "reddit_client_id = os.getenv('reddit_client_id')\n",
        "reddit_client_secret = os.getenv('reddit_client_secret')\n",
        "reddit_user_agent = os.getenv('reddit_user_agent')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Q_A_BK8wEmB"
      },
      "source": [
        "Data Extraction Code Reference from: https://colab.research.google.com/drive/15883QxK-f3Extq4dHRdqz1RdbgObzS_l?usp=sharing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "IlvFnBFHs_8l"
      },
      "outputs": [],
      "source": [
        "#===========================================================================\n",
        "# helper functions\n",
        "#===========================================================================\n",
        "\n",
        "#---------------------------------------------------------------------------\n",
        "# get all new posts from a specific subreddit as a dataframe\n",
        "def getNewPostsAsDF(r, subredditName, postLimit=10):\n",
        "  df = pd.DataFrame()   \n",
        "  subreddit = r.subreddit(subredditName) \n",
        "  for submission in subreddit.new(limit=postLimit):\n",
        "    df = df.append({'subreddit': subredditName,\n",
        "                  'post_id': submission.id,\n",
        "                  'created': datetime.utcfromtimestamp(submission.created_utc).strftime('%Y-%m-%d %H:%M:%S'),\n",
        "                  'raw_title': submission.title,\n",
        "                  'author': submission.author,\n",
        "                  'karma': round(submission.score),\n",
        "                  'awards': round(submission.total_awards_received),\n",
        "                  'permalink': submission.permalink},\n",
        "                 ignore_index = True)\n",
        "  df['created'] = pd.to_datetime(df['created'], format='%Y-%m-%d %H:%M:%S')     \n",
        "  return(df)\n",
        "\n",
        "\n",
        "#---------------------------------------------------------------------------\n",
        "# get all comments from a specific post as a dataframe\n",
        "def getAllCommentsAsDF(r, submissionId):\n",
        "  df = pd.DataFrame()   \n",
        "  res = getAllComments(r, submissionId)\n",
        "  for item in res:\n",
        "      if type(item) == praw.models.reddit.comment.Comment:\n",
        "          parent_id_clean = item.parent_id.replace(\"t1_\",\"\").replace(\"t3_\",\"\")\n",
        "          if parent_id_clean==submissionId:\n",
        "            parent_id_clean = ''\n",
        "          df = df.append({'post_id':submissionId,\n",
        "                          'comment_id': item.id,\n",
        "                          'comment_parent_id': parent_id_clean,\n",
        "                          'author': item.author,\n",
        "                          'raw_comment': item.body,\n",
        "                          'karma': round(item.score),\n",
        "                          'awards': round(item.total_awards_received)},  \n",
        "                  ignore_index = True)\n",
        "  return(df)   \n",
        "\n",
        "#---------------------------------------------------------------------------\n",
        "# get all comments on this submission as praw objects in a list\n",
        "# requires a submissionId, the id of the reddit post\n",
        "def getAllComments(r, submissionId, verbose=True):\n",
        "  submission = r.submission(submissionId)\n",
        "  comments = submission.comments\n",
        "  commentsList = []\n",
        "  for comment in comments:\n",
        "    getSubComments(comment, commentsList, verbose=verbose)\n",
        "  return commentsList\n",
        "\n",
        "#---------------------------------------------------------------------------\n",
        "# recursive function to get nexted comments that replied to other comments\n",
        "def getSubComments(comment, allComments, verbose=True):\n",
        "  allComments.append(comment)\n",
        "  if not hasattr(comment, \"replies\"):\n",
        "    replies = comment.comments()\n",
        "    if verbose: print(\"fetching (\" + str(len(allComments)) + \" comments fetched total)\")\n",
        "  else:\n",
        "    replies = comment.replies\n",
        "  for child in replies:\n",
        "    getSubComments(child, allComments, verbose=verbose) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "r2056NKYxu9V"
      },
      "outputs": [],
      "source": [
        "# create a reddit instance using the API key\n",
        "reddit = praw.Reddit(client_id=reddit_client_id,\n",
        "                     client_secret=reddit_client_secret,\n",
        "                     user_agent=reddit_user_agent)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kTl_uSlCtVnO",
        "outputId": "f0668fa5-cd83-411c-ad61-0067707d499e"
      },
      "outputs": [],
      "source": [
        "#===========================================================================\n",
        "# get the latest 500 hot posts from /r/UCLA\n",
        "latest_posts = getNewPostsAsDF(reddit, \"UCLA\", 500)\n",
        "\n",
        "# save as local CSV \n",
        "# latest_posts.to_csv('reddit_posts_UCLA.csv') \n",
        "# files.download('reddit_posts_UCLA.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tBKyzUP0tv9b",
        "outputId": "080894e6-93ba-46fa-e68c-7bb7778c35b1"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>subreddit</th>\n",
              "      <th>post_id</th>\n",
              "      <th>created</th>\n",
              "      <th>raw_title</th>\n",
              "      <th>author</th>\n",
              "      <th>karma</th>\n",
              "      <th>awards</th>\n",
              "      <th>permalink</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>UCLA</td>\n",
              "      <td>11ptbrv</td>\n",
              "      <td>2023-03-12 23:22:56</td>\n",
              "      <td>Neuroscience Upper Div Syllabus</td>\n",
              "      <td>Intrepid_Birthday651</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>/r/ucla/comments/11ptbrv/neuroscience_upper_di...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>UCLA</td>\n",
              "      <td>11ptbl9</td>\n",
              "      <td>2023-03-12 23:22:43</td>\n",
              "      <td>NCAA tickets</td>\n",
              "      <td>Slyther1208</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>/r/ucla/comments/11ptbl9/ncaa_tickets/</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>UCLA</td>\n",
              "      <td>11psc5o</td>\n",
              "      <td>2023-03-12 22:43:22</td>\n",
              "      <td>Isn’t a swipe worth around $10? This sounds cr...</td>\n",
              "      <td>EitherNoise9180</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>/r/ucla/comments/11psc5o/isnt_a_swipe_worth_ar...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>UCLA</td>\n",
              "      <td>11psan9</td>\n",
              "      <td>2023-03-12 22:41:41</td>\n",
              "      <td>whoa😩</td>\n",
              "      <td>tiredfml</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>/r/ucla/comments/11psan9/whoa/</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>UCLA</td>\n",
              "      <td>11prp3k</td>\n",
              "      <td>2023-03-12 22:17:56</td>\n",
              "      <td>Using someone else’s bruincard in dining halls</td>\n",
              "      <td>Every-Ad7132</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>/r/ucla/comments/11prp3k/using_someone_elses_b...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>495</th>\n",
              "      <td>UCLA</td>\n",
              "      <td>11l8d1r</td>\n",
              "      <td>2023-03-07 19:16:08</td>\n",
              "      <td>is RSU down??</td>\n",
              "      <td>Ok_Garbage955</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>/r/ucla/comments/11l8d1r/is_rsu_down/</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>496</th>\n",
              "      <td>UCLA</td>\n",
              "      <td>11l7qcv</td>\n",
              "      <td>2023-03-07 18:52:47</td>\n",
              "      <td>Hitch Suite Looking to Swap for a University A...</td>\n",
              "      <td>jamjamtheyam</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>/r/ucla/comments/11l7qcv/hitch_suite_looking_t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>497</th>\n",
              "      <td>UCLA</td>\n",
              "      <td>11l7mmz</td>\n",
              "      <td>2023-03-07 18:48:49</td>\n",
              "      <td>6 hour clicc equipment</td>\n",
              "      <td>ShinkaiSparkle</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>/r/ucla/comments/11l7mmz/6_hour_clicc_equipment/</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>498</th>\n",
              "      <td>UCLA</td>\n",
              "      <td>11l7faf</td>\n",
              "      <td>2023-03-07 18:41:06</td>\n",
              "      <td>Emails for letters of rec</td>\n",
              "      <td>sss10215</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>/r/ucla/comments/11l7faf/emails_for_letters_of...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>499</th>\n",
              "      <td>UCLA</td>\n",
              "      <td>11l7czz</td>\n",
              "      <td>2023-03-07 18:38:45</td>\n",
              "      <td>flixbus from DTLA on march 25 at 7:30 am</td>\n",
              "      <td>golden_snitch1202</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>/r/ucla/comments/11l7czz/flixbus_from_dtla_on_...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>500 rows × 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    subreddit  post_id             created  \\\n",
              "0        UCLA  11ptbrv 2023-03-12 23:22:56   \n",
              "1        UCLA  11ptbl9 2023-03-12 23:22:43   \n",
              "2        UCLA  11psc5o 2023-03-12 22:43:22   \n",
              "3        UCLA  11psan9 2023-03-12 22:41:41   \n",
              "4        UCLA  11prp3k 2023-03-12 22:17:56   \n",
              "..        ...      ...                 ...   \n",
              "495      UCLA  11l8d1r 2023-03-07 19:16:08   \n",
              "496      UCLA  11l7qcv 2023-03-07 18:52:47   \n",
              "497      UCLA  11l7mmz 2023-03-07 18:48:49   \n",
              "498      UCLA  11l7faf 2023-03-07 18:41:06   \n",
              "499      UCLA  11l7czz 2023-03-07 18:38:45   \n",
              "\n",
              "                                             raw_title                author  \\\n",
              "0                      Neuroscience Upper Div Syllabus  Intrepid_Birthday651   \n",
              "1                                         NCAA tickets           Slyther1208   \n",
              "2    Isn’t a swipe worth around $10? This sounds cr...       EitherNoise9180   \n",
              "3                                                whoa😩              tiredfml   \n",
              "4       Using someone else’s bruincard in dining halls          Every-Ad7132   \n",
              "..                                                 ...                   ...   \n",
              "495                                      is RSU down??         Ok_Garbage955   \n",
              "496  Hitch Suite Looking to Swap for a University A...          jamjamtheyam   \n",
              "497                             6 hour clicc equipment        ShinkaiSparkle   \n",
              "498                          Emails for letters of rec              sss10215   \n",
              "499           flixbus from DTLA on march 25 at 7:30 am     golden_snitch1202   \n",
              "\n",
              "     karma  awards                                          permalink  \n",
              "0        1       0  /r/ucla/comments/11ptbrv/neuroscience_upper_di...  \n",
              "1        1       0             /r/ucla/comments/11ptbl9/ncaa_tickets/  \n",
              "2        2       0  /r/ucla/comments/11psc5o/isnt_a_swipe_worth_ar...  \n",
              "3        2       0                     /r/ucla/comments/11psan9/whoa/  \n",
              "4        1       0  /r/ucla/comments/11prp3k/using_someone_elses_b...  \n",
              "..     ...     ...                                                ...  \n",
              "495      3       0              /r/ucla/comments/11l8d1r/is_rsu_down/  \n",
              "496      2       0  /r/ucla/comments/11l7qcv/hitch_suite_looking_t...  \n",
              "497      1       0   /r/ucla/comments/11l7mmz/6_hour_clicc_equipment/  \n",
              "498      8       0  /r/ucla/comments/11l7faf/emails_for_letters_of...  \n",
              "499      1       0  /r/ucla/comments/11l7czz/flixbus_from_dtla_on_...  \n",
              "\n",
              "[500 rows x 8 columns]"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "latest_posts"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
